{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb_PVxXaW2Qy"
   },
   "source": [
    "# <a href=\"https://miptstats.github.io/courses/ad_fivt.html\">Введение в анализ данных</a>\n",
    "## Домашнее задание 5. Компьютерное зрение & генеративные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duMi1QifW2Qz"
   },
   "source": [
    "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
    "\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_ds24_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
    "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно **ноутбук в формате `ipynb`**.\n",
    "* Следите за размером файлов. **Бот не может принимать файлы весом более 20 Мб.** Если файл получается больше, заранее разделите его на несколько.\n",
    "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
    "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "* Задача 1 &mdash; 150 баллов\n",
    "* Задача 2 &mdash; 40 баллов\n",
    "\n",
    "Баллы учитываются в <b><font color=\"green\">факультативной части</font></b> курса и не влияют на оценку по основной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWZ4wmCvW2Q0"
   },
   "outputs": [],
   "source": [
    "# Bot check\n",
    "\n",
    "# HW_ID: fpmi_ad5\n",
    "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
    "\n",
    "# Status: final\n",
    "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
    "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
    "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torchinfo"
   ],
   "metadata": {
    "id": "Oh_JpvACb7Z6"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from IPython.display import clear_output\n",
    "sns.set(font_scale=1, style='darkgrid', palette='Set2')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "metadata": {
    "id": "o2-SbeG5x3oj"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M__0kK2W2Q1"
   },
   "source": [
    "Перед выполнением задания обязательно посмотрите <a href=\"https://miptstats.github.io/courses/ad_fivt/lecture5_1.pdf\" target=\"_blank\">презентацию</a> и <a href=\"https://miptstats.github.io/courses/ad_fivt/CV_classification.html\" target=\"_blank\">ноутбук</a> про сверточные сети и классификацию, а так же <a href=\"https://miptstats.github.io/courses/ad_fivt/lecture5_2.pdf\" target=\"_blank\">презентацию</a> и <a href=\"https://miptstats.github.io/courses/ad_fivt/CV_complex_examples.html\" target=\"_blank\">ноутбук</a> про перенос стиля и генеративные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-9Z1rmVW2Q1"
   },
   "source": [
    "---\n",
    "### Задача 1. Классификация MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Цель: сравнить сверточные нейросети с разными параметрами на датасете рукописных цифр MNIST. В нем содержатся черно-белые изображения цифр, всего 10 классов для каждой цифры. Пользоваться кодом семинара можно без ограничений. Классификация MNIST намного легче, чем CIFAR, поэтому ваша задача хотя бы в одной из моделей получить 98% точности **на валидации**.\n",
    "\n",
    "> Использования слоев с семинара (свертка, pooling) более чем достаточно для достижения 98% точности на тесте. Также не делайте сеть глубокой.\n",
    "\n",
    "> Тестируйте работоспособность кода на CPU с небольшим кол-вом итераций. Если все работает, и хочется ускорить процесс, переходите на GPU.\n",
    "\n",
    "Следуйте указаниям ниже."
   ],
   "metadata": {
    "id": "FiPesei5d_6Y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим датаcет из `torchvision.datasets`."
   ],
   "metadata": {
    "id": "aZiM2W4leua-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Данные для обучения\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                           download=True,\n",
    "                                           transform=transforms.ToTensor())\n",
    "# Данные для тестирования\n",
    "val_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True,\n",
    "                                         transform=transforms.ToTensor())\n",
    "# Классы объектов в датасете\n",
    "classes = [str(i) for i in range(10)]"
   ],
   "metadata": {
    "id": "rIaFpD-8wmnc"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуализируйте несколько картинок с соответствующими метками из датасета."
   ],
   "metadata": {
    "id": "S1y77vr0eyzK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_idx, val_idx = np.random.randint(0, 10000, 2)\n",
    "print(f\"Размер картинки:{train_dataset[0][0].shape}\")\n",
    "\n",
    "# визуализируем\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(train_dataset[train_idx][0].permute(1, 2, 0))\n",
    "plt.title(f\"train[{train_idx}]: {classes[train_dataset[train_idx][1]]}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(val_dataset[val_idx][0].permute(1, 2, 0))\n",
    "plt.title(f\"val[{val_idx}]: {classes[val_dataset[val_idx][1]]}\")\n",
    "plt.axis(\"off\");"
   ],
   "metadata": {
    "id": "LnpGySak1woQ"
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер картинки:torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 400x200 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создайте генераторы батчей."
   ],
   "metadata": {
    "id": "aypFdgXdZpGQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_batch_gen = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_batch_gen = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ],
   "metadata": {
    "id": "ZxF48UxiZq2O"
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def print_epoch(epoch, num_epochs, history, t):\n",
    "    \"\"\"\n",
    "    Функция для вывода информации про эпоху.\n",
    "    :param epoch: номер эпохи\n",
    "    :param num_epochs: общее количество эпох\n",
    "    :param history: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    :param t: время эпохи в секундах\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(\"Epoch {} of {} took {:.3f} s\".format(epoch + 1, num_epochs, t))\n",
    "    print(\"  training loss: \\t{:.6f}\".format(history[\"loss\"][\"train\"][-1]))\n",
    "    print(\"  validation loss: \\t{:.6f}\".format(history[\"loss\"][\"val\"][-1]))\n",
    "    print(\n",
    "        \"  training accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            history[\"acc\"][\"train\"][-1] * 100\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            history[\"acc\"][\"val\"][-1] * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "def update_history(history, loss, acc, num_batches, mode):\n",
    "    \"\"\"\n",
    "    Функция для сохранения лосса и точности в историю.\n",
    "    :param history: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    :param loss: сумма лосса за весь батч\n",
    "    :param acc: сумма точности за весь батч\n",
    "    :param num_batches: общее количество батчей\n",
    "    :param mode: train или val\n",
    "    \"\"\"\n",
    "    # Подсчитываем лоссы и сохраняем в \"историю\"\n",
    "    loss /= num_batches\n",
    "    acc /= num_batches\n",
    "    history[\"loss\"][mode].append(loss)\n",
    "    history[\"acc\"][mode].append(acc)\n",
    "\n",
    "def get_batch_loss(\n",
    "    X_batch, y_batch, model, criterion, current_loss, current_acc\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для подсчета лосса (без backward pass).\n",
    "    :param X_batch: батч картиок X\n",
    "    :param y_batch: батч меток y\n",
    "    :param model: модель для получения логитов\n",
    "    :param criterion: функция потерь\n",
    "    :param current_loss: текущий суммарный лосс за батч\n",
    "    :param current_acc: текущая суммарная точность за батч\n",
    "    :return: лосс на данном батче; current_loss; current_acc\n",
    "    \"\"\"\n",
    "\n",
    "    # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    # Логиты на выходе модели\n",
    "    logits = model(X_batch)\n",
    "\n",
    "    # Подсчитываем лосс\n",
    "    loss = criterion(logits, y_batch.long().to(device))\n",
    "\n",
    "    # Сохраняем лоссы и точность на трейне\n",
    "    current_loss += loss.detach().cpu().numpy()\n",
    "    y_pred = logits.max(1)[1].detach().cpu().numpy()\n",
    "    current_acc += np.mean(y_batch.cpu().numpy() == y_pred)\n",
    "    return loss, current_loss, current_acc\n",
    "\n",
    "def train(\n",
    "    model, criterion, optimizer, train_batch_gen, val_batch_gen, num_epochs=40\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для обучения модели и вывода лосса и метрики во время обучения.\n",
    "\n",
    "    :param model: обучаемая модель\n",
    "    :param criterion: функция потерь\n",
    "    :param optimizer: метод оптимизации\n",
    "    :param train_batch_gen: генератор батчей для обучения\n",
    "    :param val_batch_gen: генератор батчей для валидации\n",
    "    :param num_epochs: количество эпох\n",
    "    :return: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    \"\"\"\n",
    "\n",
    "    history = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, val_loss = 0, 0\n",
    "        train_acc, val_acc = 0, 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ----------------------   ОБУЧЕНИЕ   ----------------------#\n",
    "        model.train(True)\n",
    "        # На каждой \"эпохе\" делаем полный проход по данным\n",
    "        for X_batch, y_batch in train_batch_gen:\n",
    "            # Считаем лосс, обновляем train_loss, train_acc\n",
    "            loss, train_loss, train_acc = get_batch_loss(\n",
    "                X_batch, y_batch, model, criterion, train_loss, train_acc\n",
    "            )\n",
    "\n",
    "            # Обратный проход\n",
    "            loss.backward()\n",
    "            # Шаг градиента\n",
    "            optimizer.step()\n",
    "            # Зануляем градиенты\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Подсчитываем лоссы и сохраняем в \"историю\"\n",
    "        update_history(\n",
    "            history, train_loss, train_acc, len(train_batch_gen), \"train\"\n",
    "        )\n",
    "\n",
    "        # ----------------------   ВАЛИДАЦИЯ   ----------------------#\n",
    "        model.train(False)\n",
    "        # Контекстный менеджер, отключающий подсчет градиентов\n",
    "        with torch.no_grad():\n",
    "            # Полный проход по валидационному датасету\n",
    "            for X_batch, y_batch in val_batch_gen:\n",
    "                # Считаем лосс, обновляем val_loss, val_acc\n",
    "                _, val_loss, val_acc = get_batch_loss(\n",
    "                    X_batch, y_batch, model, criterion, val_loss, val_acc\n",
    "                )\n",
    "\n",
    "        # Подсчитываем лоссы и сохраняем в \"историю\"\n",
    "        update_history(history, val_loss, val_acc, len(val_batch_gen), \"val\")\n",
    "\n",
    "        # Печатаем результаты после каждой эпохи\n",
    "        print_epoch(epoch, num_epochs, history, time.time() - start_time)\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Эксперимент 1.** Создайте хотя бы 5 сверточных нейросетей с разным количеством линейных и сверточных слоев. Должен присутствовать хотя бы 1 сверточный слой и хотя бы 1 линейный слой. Для каждой посмотрите количество параметров с помощью `torchinfo.summary`."
   ],
   "metadata": {
    "id": "eKLKBG3OfBSR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "simple_cnn_1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=1600, out_features=256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=256, out_features=10),\n",
    ").to(device)\n",
    "\n",
    "summary(simple_cnn_1, input_size=(1, 1, 28, 28))"
   ],
   "metadata": {
    "id": "XtDoy51q15s_"
   },
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n├─MaxPool2d: 1-2                         [1, 32, 13, 13]           --\n├─ReLU: 1-3                              [1, 32, 13, 13]           --\n├─Conv2d: 1-4                            [1, 64, 11, 11]           18,496\n├─MaxPool2d: 1-5                         [1, 64, 5, 5]             --\n├─ReLU: 1-6                              [1, 64, 5, 5]             --\n├─Flatten: 1-7                           [1, 1600]                 --\n├─Linear: 1-8                            [1, 256]                  409,856\n├─ReLU: 1-9                              [1, 256]                  --\n├─Linear: 1-10                           [1, 10]                   2,570\n==========================================================================================\nTotal params: 431,242\nTrainable params: 431,242\nNon-trainable params: 0\nTotal mult-adds (M): 2.87\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.24\nParams size (MB): 1.72\nEstimated Total Size (MB): 1.97\n=========================================================================================="
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 128, 3, 3]            --\n├─Conv2d: 1-1                            [1, 32, 30, 30]           896\n├─MaxPool2d: 1-2                         [1, 32, 15, 15]           --\n├─ReLU: 1-3                              [1, 32, 15, 15]           --\n├─Conv2d: 1-4                            [1, 128, 13, 13]          36,992\n├─MaxPool2d: 1-5                         [1, 128, 3, 3]            --\n├─ReLU: 1-6                              [1, 128, 3, 3]            --\n==========================================================================================\nTotal params: 37,888\nTrainable params: 37,888\nNon-trainable params: 0\nTotal mult-adds (M): 7.06\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.40\nParams size (MB): 0.15\nEstimated Total Size (MB): 0.57\n=========================================================================================="
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3),\n",
    "    nn.MaxPool2d(4),\n",
    "    nn.ReLU(),\n",
    ").to(device)\n",
    "\n",
    "summary(simple_cnn_2, input_size=(1, 3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 768]                  --\n├─Conv2d: 1-1                            [1, 16, 14, 30]           448\n├─MaxPool2d: 1-2                         [1, 16, 7, 15]            --\n├─ReLU: 1-3                              [1, 16, 7, 15]            --\n├─Conv2d: 1-4                            [1, 64, 5, 13]            9,280\n├─MaxPool2d: 1-5                         [1, 64, 2, 6]             --\n├─ReLU: 1-6                              [1, 64, 2, 6]             --\n├─Flatten: 1-7                           [1, 768]                  --\n==========================================================================================\nTotal params: 9,728\nTrainable params: 9,728\nNon-trainable params: 0\nTotal mult-adds (M): 0.79\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.09\nParams size (MB): 0.04\nEstimated Total Size (MB): 0.13\n=========================================================================================="
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_3 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    ").to(device)\n",
    "\n",
    "summary(simple_cnn_3, input_size=(1, 3, 16, 32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 32, 6, 6]             --\n├─Conv2d: 1-1                            [1, 32, 30, 30]           896\n├─MaxPool2d: 1-2                         [1, 32, 6, 6]             --\n├─ReLU: 1-3                              [1, 32, 6, 6]             --\n==========================================================================================\nTotal params: 896\nTrainable params: 896\nNon-trainable params: 0\nTotal mult-adds (M): 0.81\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.23\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.25\n=========================================================================================="
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_4 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "    nn.MaxPool2d(5),\n",
    "    nn.ReLU(),\n",
    ").to(device)\n",
    "\n",
    "summary(simple_cnn_4, input_size=(1, 3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSequential                               [1, 64, 15, 15]           --\n├─Conv2d: 1-1                            [1, 64, 61, 61]           4,160\n├─MaxPool2d: 1-2                         [1, 64, 15, 15]           --\n├─ReLU: 1-3                              [1, 64, 15, 15]           --\n==========================================================================================\nTotal params: 4,160\nTrainable params: 4,160\nNon-trainable params: 0\nTotal mult-adds (M): 15.48\n==========================================================================================\nInput size (MB): 0.07\nForward/backward pass size (MB): 1.91\nParams size (MB): 0.02\nEstimated Total Size (MB): 1.99\n=========================================================================================="
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_5 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=4, out_channels=64, kernel_size=4),\n",
    "    nn.MaxPool2d(4),\n",
    "    nn.ReLU(),\n",
    ").to(device)\n",
    "\n",
    "summary(simple_cnn_5, input_size=(1, 4, 64, 64))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучите сети, используя функцию потерь `nn.CrossEntropyLoss` и оптимизатор `torch.optim.Adam` с дефолтными параметрами."
   ],
   "metadata": {
    "id": "PQiEK0kQgUVs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T02:06:46.314950Z",
     "iopub.status.busy": "2022-11-29T02:06:46.313963Z",
     "iopub.status.idle": "2022-11-29T02:15:25.832768Z",
     "shell.execute_reply": "2022-11-29T02:15:25.831808Z",
     "shell.execute_reply.started": "2022-11-29T02:06:46.314912Z"
    },
    "id": "EnEk2EiJVJog"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 of 40 took 24.352 s\n",
      "  training loss: \t0.000006\n",
      "  validation loss: \t0.056499\n",
      "  training accuracy: \t\t\t100.00 %\n",
      "  validation accuracy: \t\t\t99.24 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(simple_cnn_1.parameters())\n",
    "\n",
    "history_cnn_1 = train(\n",
    "    simple_cnn_1,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_batch_gen,\n",
    "    val_batch_gen,\n",
    "    num_epochs=40,\n",
    ")\n",
    "# Сохраняем веса модели в файл\n",
    "torch.save(simple_cnn_1.state_dict(), \"simple_cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Постройте график лосса и график accuracy, где сравниваются все модели (на train и на val). Нужная функция есть в семинаре."
   ],
   "metadata": {
    "id": "HKeKUcptgylG"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "C-tIcHs_bZ28"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделайте вывод. Как количество разных слоев влияет на качество и время обучения?\n",
    "\n",
    "**Вывод по эксперименту 1:** <...>"
   ],
   "metadata": {
    "id": "dm2vwgrVlkj-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Эксперимент 2.** Теперь выберите лучший вариант, зафиксируйте это количество сверточных и линейных слоев и обучите хотя бы 4 сверточных нейросети, варьируя размеры ядер сверток. Например, в разном порядке поставьте ядра 3x3, 5x5."
   ],
   "metadata": {
    "id": "htYb8OWXehWB"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "vGaa6OZKfxuz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Постройте график лосса и график accuracy, где сравниваются все модели этого эксперимента (на train и на val)."
   ],
   "metadata": {
    "id": "cgvL8CP6fype"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "dW4ZP422fypf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделайте вывод. Как размеры ядер влияют на качество и время обучения?\n",
    "\n",
    "**Вывод по эксперименту 2:** <...>"
   ],
   "metadata": {
    "id": "MUy9v-IAltAP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Анализ лучшей модели.** Выберите лучшую конфигурацию из всех по accuracy на валидации. Она должна быть не меньше 98%."
   ],
   "metadata": {
    "id": "bqLZr0CCdV-p"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ztRtP5VtgQ3h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проведите еще один проход валидации выбранной моделью по всему датасету. В нем посчитайте точность по каждому классу и соберите информацию о неправильных предсказаниях. Равномерна ли точность по отношению к классам? Покажите 10-20 примеров, на которых нейросеть выдала неправильную метку. Что можно о них сказать?"
   ],
   "metadata": {
    "id": "TMPEvu2bg3Zc"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "A94g5BGz6uU4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVfdfsXZnhcs"
   },
   "source": [
    "**Ответ:** <...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_EvDaB7W2Q2"
   },
   "source": [
    "**Вывод по всей задаче:** <...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWHsMVWwW2Q2"
   },
   "source": [
    "---\n",
    "### Задача 2. Перенос стиля"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Здесь вы потренируетесь в работе с картинками и составлением промптов. Используя код с <a href=\"https://miptstats.github.io/courses/ad_fivt/CV_complex_examples.html\" target=\"_blank\">семинара</a>, проведите перенос стиля на хотя бы 3 своих примерах.\n",
    "\n",
    "> Заметьте, что в примерах с семинара в качестве картинок стиля и контента использовались картинки среднего разрешения. Если возникают проблемы: оптимизация останавливается на 0-й эпохе и не создает картинку; loss в какой-то момент стал nan; нехватка RAM; &mdash; то либо уменьшите разрешение ваших картинок, либо попробуйте картинку полегче."
   ],
   "metadata": {
    "id": "33gKkfQz2mIx"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Syn9JDq04ISQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь для каждой пары контекст-стиль попытайтесь сгенерировать картинку с таким контекстом и стилем с помощью диффузионной модели, рассмотренной на семинаре, задав нужный промпт."
   ],
   "metadata": {
    "id": "I2yeDQMz4IiY"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "oQ_6F1NP47ot"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPoMmyGgW2Q3"
   },
   "source": [
    "**Вывод:**\n",
    "<...>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
